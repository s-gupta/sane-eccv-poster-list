<!DOCTYPE html>
<!-- saved from url=(0053)https://papers.eccv2020.eu/papers/category/spotlight/ -->
<html lang="en" dir="ltr"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
	<title>ECCV - Papers and Presentations</title>
	<link rel="stylesheet" href="./spotlights_files/uikit.min.css">
	<script src="./spotlights_files/jquery.min.js"></script>
	<script src="./spotlights_files/uikit.min.js"></script>
	<script src="./spotlights_files/uikit-icons.min.js"></script>
	<style type="text/css">
		#ccs-nav {
			background-color: #28a5f0;
			background-image: url("/static/images/DigitalBackground-25.png");
			background-repeat: repeat;
		}
		#ccs-nav li a {
			color: #fff;
			font-weight: bold;
		}
		#ccs-nav .uk-search {
			background-color: white;
			width: 200px;
		}
		#ccs-nav .uk-search-icon {
			width: 20px;
			padding-left: 5px;
		}
		#ccs-nav .uk-search-input {
			font-size: 1.0rem;
			padding-left: 30px;
		}
		#ccs-nav .uk-logo img {
			width: 70px;
		}
		#eccv-votes button.eccv-vote {
			background-color: #eee;
			color: #bbb;
		}
		#eccv-votes button.eccv-vote span.uk-icon {
			display: none;
		}
		#eccv-votes button.eccv-active {
			background-color: #adfb96;
			color: #22a286;
		}
		#eccv-votes button.eccv-active span.uk-icon {
			display: inline-block;
		}
		.eccv-question {
			cursor: pointer;
		}
		.eccv-question-target {
			display: none;
		}

		body {
			background-color: #eee;
			background-image: url("/static/images/DigitalBackground-15.png");
			background-repeat: repeat;
		}
		.ccs-no-profile-image {
			display: block;
			width: 40px;
			height: 40px;
			background-color: #ccc;
			border: 1px dotted #aaa;
			text-align: center;
			line-height: 40px;
			font-weight: bold;
			border-radius: 20px;
		}
	</style>
	
</head>
<body>
<nav id="ccs-nav" class="uk-navbar-container uk-navbar" uk-navbar="">
	<div class="uk-navbar-left">
		<ul class="uk-navbar-nav">
			<li><a class="uk-navbar-item uk-logo" href="https://papers.eccv2020.eu/"><img src="./spotlights_files/eccv-online-logo_A.png" alt="ECCV Online"></a></li>
			<li><a class="uk-navbar-item" href="https://papers.eccv2020.eu/">Papers and Presentations</a></li>
		</ul>
	</div>
	<div class="uk-navbar-right">
		<div class="uk-navbar-item">
			<form method="GET" action="https://papers.eccv2020.eu/papers/search/" class="uk-search uk-search-navbar">
				<span uk-search-icon="" class="uk-icon uk-search-icon"><svg width="24" height="24" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" data-svg="search-navbar"><circle fill="none" stroke="#000" stroke-width="1.1" cx="10.5" cy="10.5" r="9.5"></circle><line fill="none" stroke="#000" stroke-width="1.1" x1="23" y1="23" x2="17" y2="17"></line></svg></span>
				<input class="uk-search-input uk-form-small" name="q" type="search" placeholder="Search...">
			</form>
		</div>
		<ul class="uk-navbar-nav">
			
				<li><a href="https://papers.eccv2020.eu/">saurabhg@illinois.edu</a></li>
			
		</ul>
	</div>
</nav>
<div class="uk-container uk-padding-large">

<div class="uk-grid-small uk-flex-center uk-grid uk-grid-stack" uk-grid="">
	<div class="uk-width-1-1 uk-first-column">
		<h2>Papers in Category Spotlight</h2>

		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3663/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4354 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied Tasks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Unnat Jain, Luca Weihs, Eric Kolve, Ali Farhadi, Svetlana Lazebnik, Aniruddha Kembhavi, Alexander Schwing</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We introduce FurnMove, a collaborative embodied task requiring close coordination between multiple visual agents, and propose a method that goes beyond independent action sampling from marginal policies.
Our dataset, code, and pre-trained models are available at https://unnat.github.io/cordial-sync</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/849/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2282 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">TIDE: A General Toolbox for Identifying Object Detection Errors</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Daniel Bolya, Sean Foley, James Hays, Judy Hoffman</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We define errors in a way that isolates their contribution to overall performance, and then we use that to produce comprehensive analysis.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3657/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2351 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">A Generalization of Otsu's Method and Minimum Error Thresholding</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jonathan T. Barron</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Classic and old algorithm for image thresholding can be seen as special cases of a simple Bayesian model, and this tiny change lets classic algorithms beats giant CNNs at image thresholding.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/22/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3000 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">TSIT: A Simple and Versatile Framework for Image-to-Image Translation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Liming Jiang, Changxu Zhang, Mingyang Huang, Chunxiao Liu, Jianping Shi, Chen Change Loy</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A simple and versatile framework for image-to-image translation.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1207/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4261 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">REVISE: A Tool for Measuring and Mitigating Bias in Visual Datasets</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Angelina Wang, Arvind Narayanan, Olga Russakovsky</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A tool that automatically detects possible forms of bias in a visual dataset along the axes of object-based, gender-based, and geography-based patterns, and from which next steps for mitigation are suggested.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/223/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3227 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">A Unified Framework of Surrogate Loss by Refactoring and Interpolation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Lanlan Liu, Mingzhe Wang, Jia Deng</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3977/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3121 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">AABO: Adaptive Anchor Box Optimization for Object Detection via Bayesian Sub-sampling</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Wenshuo Ma, Tingzhong Tian, Hang Xu, Yimin Huang, Zhenguo Li</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4458/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4379 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Active Perception using Light Curtains for Autonomous Driving</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Siddharth Ancha, Yaadhav Raaj, Peiyun Hu, Srinivasa G. Narasimhan, David Held</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1605/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4281 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Adaptive Computationally Efficient Network for Monocular 3D Hand Pose Estimation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhipeng Fan, Jun Liu, Yao Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We proposed an Adaptive Computation Efficient network for hand pose estimation, which dynamically allocates computation resources for pose estimation based on pose estimation difficulty of the current frame.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3456/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1085 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Adaptive Margin Diversity Regularizer for handling Data Imbalance in Zero-Shot SBIR</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Titir Dutta, Anurag Singh, Soma Biswas</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Handling data imbalance for zero-shot sketch based image retrieval using a adaptive margin diversity regularizer.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4383/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2363 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Adversarial T-shirt! Evading Person Detectors in A Physical World</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Kaidi Xu, Gaoyuan Zhang, Sijia Liu, Quanfu Fan, Mengshu Sun, Hongge Chen, Pin-Yu Chen, Yanzhi Wang, Xue Lin</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A physical adversarial T-shirt to fool object detectors for detecting moving persons.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2767/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2320 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Are Labels Necessary for Neural Architecture Search?</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Chenxi Liu, Piotr Doll'ar, Kaiming He, Ross Girshick, Alan Yuille, Saining Xie</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Images alone can identify high-quality neural architectures; labels are not necessary.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2826/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1174 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Associative Alignment for Few-shot Image Classification</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Arman Afrasiyabi, Jean-Francc}ois Lalonde, Christian Gagn'e</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">This paper proposes the idea of associative alignment for leveraging part of the base data by aligning the novel training instances to the closely related ones in the base training set.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4577/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3296 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">SoundSpaces: Audio-Visual Navigation in 3D Environments</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Changan Chen, Unnat Jain, Carl Schissler, Sebastia Vicenc Amengual Gari, Ziad Al-Halah, Vamsi Krishna Ithapu, Philip Robinson, and Kristen Grauman</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">SoundSpaces: embodied perception for audio-visual navigation, where an agent learns to navigate to a sound source in a 3D environment</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1564/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2300 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Huiyu Wang, Yukun Zhu, Bradley Green, Hartwig Adam, Alan Yuille, Liang-Chieh Chen</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2776/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3266 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">BLSM: A Bone-Level Skinned Model of the Human Mesh</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Haoyang Wang, Riza Alp G"uler, Iasonas Kokkinos, George Papandreou, Stefanos Zafeiriou</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6959/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4439 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jize Cao, Zhe Gan, Yu Cheng, Licheng Yu, Yen-Chun Chen, Jingjing Liu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A detailed analysis of current large-scale pre-trained vision-and-language models</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3665/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2257 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Big Transfer (BiT): General Visual Representation Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Carefully executed pre-training of large visual models on large supervised data (~300 million images) results in unprecedented transfer performance.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1530/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2055 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Binarized Neural Network for Single Image Super Resolution</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jingwei Xin, Nannan Wang, Xinrui Jiang, Jie Li, Heng Huang, Xinbo Gao</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">This work is devoted to investigate the binary neural network-based (BNN-based) SISR problem, and propose an simple but efficient binary SISR model.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4404/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4161 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Bounding-box Channels for Visual Relationship Detection</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Sho Inayoshi, Keita Otani, Antonio Tejero-de-Pablos, Tatsuya Harada</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3365/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2141 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">CLIFFNet for Monocular Depth Estimation with Hierarchical Embedding Loss</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Lijun Wang, Jianming Zhang, Yifan Wang, Huchuan Lu, Xiang Ruan</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">CLIFFNet for Monocular Depth Estimation with Hierarchical Embedding Loss</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2390/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4086 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">CPGAN: Content-Parsing Generative Adversarial Networks for Text-to-Image Synthesis</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jiadong Liang, Wenjie Pei, Feng Lu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present a novel model for text-to-image synthesis by deeply parsing the content on both text and image sides.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3499/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1088 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Calibration-free Structure-from-Motion with Calibrated Radial Trifocal Tensors</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Viktor Larsson, Nicolas Zobernig, Kasim Taskin, Marc Pollefeys</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Structure-from-Motion with 1D Radial Camera model</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1624/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3050 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Chained-Tracker: Chaining Paired Attentive Regression Results for End-to-End Joint Multiple-Object Detection and Tracking</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jinlong Peng, Changan Wang, Fangbin Wan, Yang Wu, Yabiao Wang, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, Yanwei Fu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Chained-Tracker can simultaneously give the detection and tracking results of two adjacent frames and then use simple data association rules to connect each adjacent pairs just like a chain.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3913/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4154 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Character Grounding and Re-Identification in Story of Videos and Text Descriptions</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Youngjae Yu, Jongseok Kim, Heeseung Yun, Jiwan Chung, Gunhee Kim</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose the CiSIN model that can jointly tackle character grounding and re-identification in both video and text narratives. It achieves the best performance so far in two benchmarks datasets: LSMDC 2019 challenge and M-VAD Names dataset.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/990/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2033 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Circumventing Outliers of AutoAugment with Knowledge Distillation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Longhui Wei, An Xiao, Lingxi Xie, Xiaopeng Zhang, Xin Chen, Qi Tian</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Using knowledge distillation to filter out less informative data generated by AutoAugment</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6053/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2231 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhensheng Shi, Cheng Guan, Liangjie Cao, Qianqian Li, Ju Liang, Zhaorui Gu, Haiyong Zheng, Bing Zheng</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose CoTeRe-Net which discovers the collaborative ternary relations (channel, temporal, spatial) in videos. The CoTeRe-Net can discover relations of both implicit and explicit cues, unlike most existing relation models.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1362/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4043 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Collaborative Learning of Gesture Recognition and 3D Hand Pose Estimation with Multi-Order Feature Analysis</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Siyuan Yang, Jun Liu, Shijian Lu, Meng Hwa Er, Alex C. Kot</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a new method for gesture recognition and 3D hand pose estimation from RGB videos</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3385/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4140 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Collaborative Video Object Segmentation by Foreground-Background Integration</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zongxin Yang, Yunchao Wei, Yi Yang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4296/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1115 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Connecting Vision and Language with Localized Narratives</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jordi Pont-Tuset, Jasper Uijlings, Soravit Changpinyo, Radu Soricut, Vittorio Ferrari</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2918/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3271 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Contact and Human Dynamics from Monocular Video</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Davis Rempe, Leonidas J. Guibas, Aaron Hertzmann, Bryan Russell, Ruben Villegas, Jimei Yang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present a method to recover physically-plausible human motion from monocular RGB video.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1327/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4268 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Contrastive Learning for Weakly Supervised Phrase Grounding</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Tanmay Gupta, Arash Vahdat, Gal Chechik, Xiaodong Yang, Jan Kautz, Derek Hoiem</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We formulate weakly-supervised phrase grounding as maximizing a lower bound on mutual information between image-regions and caption-words.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6314/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3219 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Controlling Style and Semantics in Weakly-Supervised Image Generation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Dario Pavllo, Aurelien Lucchi, Thomas Hofmann</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A modular conditioning scheme for generative models that provides control over both style and semantics of complex scenes</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/597/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1016 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Convolutional Occupancy Networks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Songyou Peng, Michael Niemeyer, Lars Mescheder, Marc Pollefeys, Andreas Geiger</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/492/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3012 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Corner Proposal Network for Anchor-free, Two-stage Object Detection</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Kaiwen Duan, Lingxi Xie, Honggang Qi, Song Bai, Qingming Huang, Qi Tian</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A two-stage object detection method which groups corner keypoints into proposals and judges them using light-weighted classifiers</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4727/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2367 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Counterfactual Vision-and-Language Navigation via Adversarial Path Sampler</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Tsu-Jui Fu, Xin Eric Wang, Matthew F. Peterson,Scott T. Grafton, Miguel P. Eckstein, William Yang Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present a model-agnostic adversarial path sampler (APS) that learns to sample challenging paths that force the navigator to improve based on the navigation performance.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2873/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1070 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Cyclic Functional Mapping: Self-supervised Correspondence between Non-isometric Deformable Shapes</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Dvir Ginzburg, Dan Raviv</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We presented a self-supervised architecture based on a cycle-consistent network for the dense shape correspondence problem working in the spectral domain.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2616/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3183 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">DEMEA: Deep Mesh Autoencoders for Non-Rigidly Deforming Objects</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Edgar Tretschk, Ayush Tewari, Michael Zollh"ofer, Vladislav Golyanik, Christian Theobalt</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a general purpose deep mesh autoencoder which adds a novel embedded deformation layer to a graph-convolutional mesh autoencode.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/922/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4024 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">DSA: More Efficient Budgeted Pruning via Differentiable Sparsity Allocation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xuefei Ning, Tianchen Zhao, Wenshuo Li, Peng Lei, Yu Wang, Huazhong Yang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">DSA solves the budgeted pruning problem efficiently in a gradient-based way.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3335/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2140 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">DTVNet: Dynamic Time-lapse Video Generation via Single Still Image</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jiangning Zhang, Chao Xu, Liang Liu, Mengmeng Wang, Xia Wu, Yong Liu, Yunliang Jiang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3099/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4343 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Deep Feedback Inverse Problem Solver</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Wei-Chiu Ma, Shenlong Wang, Jiayuan Gu, Sivabalan Manivasagam, Antonio Torralba, Raquel Urtasun</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2754/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1066 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">DH3D: Deep Hierarchical 3D Descriptors for Robust Large-Scale 6DoF Relocalization</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Juan Du, Rui Wang, Daniel Cremers</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Point cloud based large-scale relocalization using hierarchical 3D descriptors</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/362/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4230 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Deep Reflectance Volumes: Relightable Reconstructions from Multi-View Photometric Images</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Sai Bi, Zexiang Xu, Kalyan Sunkavalli, Milovs} Havs}an, Yannick Hold-Geoffroy, David Kriegman, Ravi Ramamoorthi</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4452/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4378 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">DeepGMR: Learning Latent Gaussian Mixture Models for Registration</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Wentao Yuan, Benjamin Eckart, Kihwan Kim, Varun Jampani, Dieter Fox, Jan Kautz</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">The first deep learning based probabilistic point cloud registration algorithm: learns pose-invariant point-to-latent distribution (GMM) correspondences.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2666/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4105 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Dense Hybrid Recurrent Multi-view Stereo Net with Dynamic Consistency Checking</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jianfeng Yan, Zizhuang Wei, Hongwei Yi, Mingyu Ding, Runze Zhang, Yisong Chen, Guoping Wang, Yu-Wing Tai</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">we propose a dense hybrid recurrent multi-view stereo net with dynamic consistency checking for accurate dense point cloud reconstruction.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5685/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4405 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Directional Temporal Modeling for Action Recognition</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xinyu Li, Bing Shuai, Joseph Tighe</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A clip-level temporal modeling method for action recognition</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1631/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3051 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Distribution-Balanced Loss for Multi-Label Classification in Long-Tailed Datasets</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Tong Wu, Qingqiu Huang, Ziwei Liu, Yu Wang, Dahua Lin</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We proposed a distribution-balanced loss to deal with multi-label classification in long-tailed datasets</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4867/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1125 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Dynamic Group Convolution for Accelerating Convolutional Neural Networks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhuo Su, Linpu Fang, Wenxiong Kang, Dewen Hu, Matti Pietik"ainen, Li Liu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Using Dynamic Group Convolution to accelerate existing convolutional neural networks.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2988/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2335 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Entropy Minimisation Framework for Event-based Vision Model Estimation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Urbano Miguel Nunes, Yiannis Demiris</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Event-based framework for arbitrary model estimation by minimising the modelled events' entropy.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4677/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2197 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Erasing Appearance Preservation in Optimization-based Smoothing</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Lvmin Zhang, Chengze Li, Yi JI, Chunping Liu, Tien-tsin Wong</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Image smoothing with the appearance preserving energy partially erased</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2755/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1067 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Face Super-Resolution Guided by 3D Facial Priors</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xiaobin Hu, Wenqi Ren, John LaMaster, Xiaochun Cao, Xiaoming Li, Zechao Li, Bjoern Menze, Wei Liu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a novel face super resolution method that explicitly incorporates 3D facial priors which grasp the sharp facial structures.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2983/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4336 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Few-Shot Scene-Adaptive Anomaly Detection</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yiwei Lu, Frank Yu, Mahesh Kumar Krishna Reddy, Yang Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/467/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2274 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">COCO-FUNIT: Few-Shot Unsupervised Image Translation with a Content Conditioned Style Encoder</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Kuniaki Saito, Kate Saenko, Ming-Yu Liu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A new few-shot unsupervised image-to-image translation framework that can achieve photorealistic outputs for challenging datasets.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3831/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2163 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Few-shot Action Recognition with Permutation-invariant Attention</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Hongguang Zhang, Li Zhang, Xiaojuan Qi, Hongdong Li, Philip H. S. Torr, Piotr Koniusz</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4809/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4173 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Filter Style Transfer between Photos</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jonghwa Yim, Jisung Yoo, Won-joon Do, Beomsu Kim, Jihwan Choe</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1488/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2298 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">GAN Slimming: All-in-One GAN Compression by A Unified Optimization Framework</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Haotao Wang, Shupeng Gui, Haichuan Yang, Ji Liu, Zhangyang Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2534/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3180 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">GRAB: A Dataset of Whole-Body Human Grasping of Objects</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Omid Taheri, Nima Ghorbani, Michael J. Black, Dimitrios Tzionas</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We provide a large scale dataset of whole-body grasps for 3D objects and  we use the dataset to train a generative model for hand grasping poses of unseen 3D objects.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5554/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4398 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">GeLaTO: Generative Latent Textured Objects</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Ricardo Martin-Brualla, Rohit Pandey, Sofien Bouaziz, Matthew Brown, Dan B Goldman</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Use coarse geometry and learned textures to model object classes for 3D reconstruction</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1977/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3254 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Generative Sparse Detection Networks for 3D Single-shot Object Detection</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">JunYoung Gwak, Christopher Choy, Silvio Savarese</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose the Generative Sparse Detection Network, a fully-convolutional single-shot 3D object detector that efficiently processes large-scale point clouds with high accuracy.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1987/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2309 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Grounded Situation Recognition</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Sarah Pratt, Mark Yatskar, Luca Weihs, Ali Farhadi, Aniruddha Kembhavi</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We introduce Grounded Situation Recognition and SWiG, a new task and dataset for semantic, grounded, image summarization and show that joint prediction and training is critical for success.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4749/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4171 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Guided Deep Decoder: Unsupervised Image Pair Fusion</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Tatsumi Uezato, Danfeng Hong, Naoto Yokoya, Wei He</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a new unsupervised method that can be applied to various image fusion tasks without training data.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/148/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3004 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">HMOR: Hierarchical Multi-Person Ordinal Relations for Monocular Multi-Person 3D Pose Estimation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Can Wang, Jiefeng Li, Wentao Liu, Chen Qian, Cewu Lu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We proposed a novel form of supervision - HMOR, to explicitly leverage the multi-person relationship for 3D pose estimation.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3120/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4344 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Hallucinating Visual Instances in Total Absentia</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jiayan Qiu, Yiding Yang, Xinchao Wang, Dacheng Tao</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1676/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3174 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Hamiltonian Dynamics for Real-World Shape Interpolation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Marvin Eisenberger, Daniel Cremers</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1526/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4046 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Human Interaction Learning on 3D Skeleton Point Clouds for Video Violence Recognition</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yukun Su, Guosheng Lin, Jinhui Zhu, Qingyao Wu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/415/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2012 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Identity-Guided Human Semantic Parsing for Person Re-Identification</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Kuan Zhu, Haiyun Guo, Zhiwei Liu, Ming Tang, Jinqiao Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose the identity-guided human semantic parsing approach for aligned person re-ID, which can locate both the human body parts and personal belongings at pixel-level only with person identity labels.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5672/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4404 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Improving Vision-and-Language Navigation with Image-Text Pairs from the Web</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Arjun Majumdar, Ayush Shrivastava, Stefan Lee, Peter Anderson, Devi Parikh, Dhruv Batra</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We demonstrate that visual grounding learned from image-text pairs from the web can be used to significantly improve performance on the embodied AI task of Vision-and-Language Navigation (VLN).</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3995/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1101 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Indirect Local Attacks for Context-aware Semantic Segmentation Networks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Krishna Kanth Nakka, Mathieu Salzmann</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Susceptibility of state-of-the-art segmentation networks to indirect local perturbations</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4521/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4165 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Invertible Neural BRDF for Object Inverse Rendering</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhe Chen, Shohei Nobuhara, Ko Nishino</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A new invertible NN-based BRDF model and its use in inverse rendering</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4860/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1123 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">JGR-P2O: Joint Graph Reasoning based Pixel-to-Offset Prediction Network for 3D Hand Pose Estimation from a Single Depth Image</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Linpu Fang, Xingyan Liu, Li Liu, Hang Xu, Wenxiong Kang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A GCN based model for 3D hand pose estimation from single depth images.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6360/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4425 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Jointly learning visual motion and confidence from local patches in event cameras</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Daniel R. Kepple, Daewon Lee, Colin Prepsius, Volkan Isler, Il Memming Park, Daniel D. Lee</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2763/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2113 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Label Propagation with Augmented Anchors: A Simple Semi-Supervised Learning baseline for Unsupervised Domain Adaptation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yabin Zhang, Bin Deng, Kui Jia, Lei Zhang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Investigating SSL techniques for UDA.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3994/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4220 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Large Scale Holistic Video Understanding</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Ali Diba, Mohsen Fayyaz, Vivek Sharma, Manohar Paluri, J"u}rgen Gall, Rainer Stiefelhagen, Luc Van Gool</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">This paper presents the idea of holistic video understanding and the dataset.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/526/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4010 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning Delicate Local Representations for Multi-Person Pose Estimation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yuanhao Cai, Zhicheng Wang, Zhengxiong Luo, Binyi Yin, Angang Du, Haoqian Wang, Xiangyu Zhang, Xinyu Zhou, Erjin Zhou, Jian Sun</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Human Pose Estimation, COCO, MPII, Feature Aggregation, Attention Mechanism</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3119/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4123 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning From Multiple Experts: Self-paced Knowledge Distillation for Long-tailed Classification</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Liuyu Xiang, Guiguang Ding, Jungong Han</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a divide-and-conquer style self-paced knowledge distillation strategy for long-tailed classification.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/462/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2273 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning Gradient Fields for Shape Generation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Ruojin Cai, Guandao Yang, Hadar Averbuch-Elor, Zekun Hao, Serge Belongie, Noah Snavely, Bharath Hariharan</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Learning Gradient Fields for Shape Generation</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2019/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3063 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Shaoxiang Chen, Wenhao Jiang, Wei Liu, Yu-Gang Jiang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a novel method for learning pairwise modality interactions to better exploit complementary information for each pair of modalities in videos, and thus benefit high-level video understanding tasks.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6025/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4419 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning Multi-layer Latent Variable Model via Variational Optimization of Short Run MCMC for Approximate Inference</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Erik Nijkamp, Bo Pang, Tian Han, Linqi Zhou, Song-Chun Zhu, Ying Nian Wu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a short run inference dynamics to learn generative models with multiple layers of latent variables.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/591/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4013 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning Open Set Network with Discriminative Reciprocal Points</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Guangyao Chen, Limeng Qiao, Yemin Shi, Peixi Peng, Jia Li, Tiejun Huang, Shiliang Pu, Yonghong Tian</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3984/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2171 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning Visual Context by Comparison</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Minchul Kim, Jongchan Park, Seil Na, Chang Min Park, Donggeun Yoo</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose Attend-and-Comapare Module that models useful contextual information by comparison for recognition tasks.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2473/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3262 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning to Factorize and Relight a City</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Andrew Liu, Shiry Ginosar, Tinghui Zhou, Alexei A. Efros, Noah Snavely</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We use Google Street View Time Machine to disentangle the world into temporally varying elements and permanent ones</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1694/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4283 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning to Scale Multilingual Representations for Vision-Language Tasks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Andrea Burns, Donghyun Kim, Derry Wijaya, Kate Saenko, Bryan A. Plummer</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present a scalable multilingual training process for vision-language tasks.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/544/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1015 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning to Plan with Uncertain Topological Maps</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Edward Beeching, Jilles Dibangoye, Olivier Simonin, Christian Wolf</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We plan in 3D environments using graphs with noisy connectivity and use visual features to overcome missing information.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2449/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1042 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">MTI-Net: Multi-Scale Task Interaction Networks for Multi-Task Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Simon Vandenhende, Stamatios Georgoulis, Luc Van Gool</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A novel architecture for multi-task dense prediction tasks.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/193/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2266 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Mask2CAD: 3D Shape Prediction by Learning to Segment and Retrieve</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Weicheng Kuo, Anelia Angelova, Tsung-Yi Lin, Angela Dai</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose Mask2CAD as an alternative to Mesh R-CNN that learns instance segmentation and 3D shape embeddings jointly for 3D shape prediction.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1761/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3055 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Feature Representation Matters: End-to-End Learning for Reference-based Image Super-resolution</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yanchun Xie, Jimin Xiao, Mingjie Sun, Chao Yao, Kaizhu Huang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">reference based super-resolution</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/366/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4231 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Memory-augmented Dense Predictive Coding for Video Representation Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Tengda Han, Weidi Xie, Andrew Zisserman</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6496/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4427 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">A unifying mutual information view of metric learning: cross-entropy vs. pairwise losses</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Malik Boudiaf, J'er^ome Rony, Imtiaz Masud Ziko, Eric Granger, Marco Pedersoli, Pablo Piantanida, Ismail Ben Ayed</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4407/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1119 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Minimal Rolling Shutter Absolute Pose with Unknown Focal Length and Radial Distortion</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zuzana Kukelova, Cenek Albl, Akihiro Sugimoto, Konrad Schindler, Tomas Pajdla</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Minimal Rolling Shutter Absolute Pose with Unknown Focal Length and Radial Distortion</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6100/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1148 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Modeling the Effects of Windshield Refraction for Camera Calibration</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Frank Verbiest, Marc Proesmans, Luc Van Gool</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2710/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3082 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">MovieNet: A Holistic Dataset for Movie Understanding</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Qingqiu Huang, Yu Xiong, Anyi Rao, Jiaze Wang, Dahua Lin</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">This paper proposed a holistic dataset for movie understanding, which can support various tasks from low-level to high-level.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5821/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2224 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Multi-Temporal Recurrent Neural Networks For Progressive Non-Uniform Single Image Deblurring With Incremental Temporal Training</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Dongwon Park, Dong Un Kang, Jisoo Kim, Se Young Chun</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose multi-temporal approach for image deblurring to improve performance with small network and fast computation as an alternative to conventional multi-scale approach</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1915/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3060 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Multimodal Shape Completion via Conditional Generative Adversarial Networks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Rundi Wu, Xuelin Chen, Yixin Zhuang, Baoquan Chen</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1710/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3175 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Multi-modal Transformer for Video Retrieval</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Valentin Gabeur, Chen Sun, Karteek Alahari, Cordelia Schmid</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Cross-modal framework for video-retrieval using the Transformer architecture.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/672/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3234 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Multi-person 3D Pose Estimation in Crowded Scenes Based on Multi-View Geometry</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">He Chen, Pengfei Guo, Pengfei Li, Gim Hee Lee, Gregory Chirikjian</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2317/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4078 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Negative Margin Matters: Understanding Margin in Few-shot Classification</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Bin Liu, Yue Cao, Yutong Lin, Qi Li, Zheng Zhang, Mingsheng Long, Han Hu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Introduces a negative margin loss to metric learning based few-shot learning methods and achieves state-of-the-art accuracy. To understand why the negative margin loss performs well, we provide both the intuitive and theoretical analysis.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/574/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4237 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Neural Design Network: Graphic Layout Generation with Constraints</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Hsin-Ying Lee, Lu Jiang, Irfan Essa, Phuong B Le, Haifeng Gong, Ming-Hsuan Yang, Weilong Yang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2636/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1060 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Neural Object Learning for 6D Pose Estimation Using a Few Cluttered Images</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Kiru Park, Timothy Patten, Markus Vincze</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Neural Object Learning (NOL), that creates synthetic images of objects in arbitrary poses by combining only a few observations from cluttered images.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5021/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3147 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Object-Contextual Representations for Semantic Segmentation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yuhui Yuan, Xilin Chen, Jingdong Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3594/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3281 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Occupancy Anticipation for Efficient Exploration and Navigation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Santhosh K. Ramakrishnan, Ziad Al-Halah, Kristen Grauman</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Propose occupancy map anticipation model for efficient exploration and navigation in embodied agents with Deep RL</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3087/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3092 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">PIoU Loss: Towards Accurate Oriented Object Detection in Complex Environments</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhiming Chen, Kean Chen, Weiyao Lin, John See, Hui Yu, Yan Ke, Cong Yang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6254/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4209 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">PROFIT: A Novel Training Method for sub-4-bit MobileNet Models</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Eunhyeok Park, Sungjoo Yoo</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Sub 4-bit quantization method for optimized networks, i.e. MobileNet-v1, v2, v3 and MNasNet</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2323/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4079 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Particularity beyond Commonality: Unpaired Identity Transfer with Multiple References</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Ruizheng Wu, Xin Tao, Yingcong Chen, Xiaoyong Shen, Jiaya Jia</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A multiple reference method for unpaired identity transfer tasks</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2986/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2334 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Personalized Face Modeling for Improved Face Reconstruction and Motion Retargeting</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Bindita Chaudhuri, Noranart Vesdapunt, Linda Shapiro, Baoyuan Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose an end-to-end learning framework that learns user-specific personalized adjustments and user-independent facial motion.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5471/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4192 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Photon-Efficient 3D Imaging with A Non-Local Neural Network</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jiayong Peng, Zhiwei Xiong, Xin Huang, Zheng-Ping Li, Dong Liu, Feihu Xu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/495/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1166 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">PhraseClick: Toward Achieving Flexible Interactive Segmentation by Phrase and Click</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Henghui Ding, Scott Cohen, Brian Price, Xudong Jiang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A more flexible interactive segmentation network that accepts both click and phrase as interaction input.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2707/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1062 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Pixel-Pair Occlusion Relationship Map (P2ORM): Formulation, Inference \&amp; Application</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xuchong Qiu, Yang Xiao, Chaohui Wang, Renaud Marlet</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We redefine oriented occlusion boundary estimation, outperforming existing methods, and show how to use it to refine depth maps.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2965/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1073 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Points2Surf Learning Implicit Surfaces from Point Clouds</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Philipp Erler, Paul Guerrero, Stefan Ohrhallinger, Niloy J. Mitra, Michael Wimmer</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Patch-based surface reconstruction from point clouds.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/893/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4253 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">PointContrast: Unsupervised Pre-training for 3D Point Cloud Understanding</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Saining Xie, Jiatao Gu, Demi Guo, Charles R. Qi, Leonidas Guibas, Or Litany</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Unsupervised pre-training made work for 3D deep learning.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/378/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1012 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">PointMixup: Augmentation for Point Clouds</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yunlu Chen, Vincent Tao Hu, Efstratios Gavves, Thomas Mensink, Pascal Mettes, Pengwan Yang, Cees G. M. Snoek</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2950/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4329 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">PointPWC-Net: Cost Volume on Point Clouds for (Self-)Supervised Scene Flow Estimation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Wenxuan Wu, Zhi Yuan Wang, Zhuwen Li, Wei Liu, Li Fuxin</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a novel end-to-end deep scene flow model, called PointPWC-Net, and a self-supervised loss that directly process 3D point cloud scenes with large motions in a coarse-to-fine fashion.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4571/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4167 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Practical Deep Raw Image Denoising on Mobile Devices</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yuzhi Wang, Haibin Huang, Qin Xu, Jiaming Liu, Yiqun Liu, Jue Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4294/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4367 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Predicting Visual Overlap of Images Through Interpretable Non-Metric Box Embeddings</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Anita Rau, Guillermo Garcia-Hernando, Danail Stoyanov, Gabriel J. Brostow, Daniyar Turmukhambetov</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Asymmetric embedding of 2+ images reveals which image is zoomed out version of the other; this also helps correct for scale differences.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5975/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3157 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">ProgressFace: Scale-Aware Progressive Learning for Face Detection</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jiashu Zhu, Dong Li, Tiantian Han, Lu Tian, Yi Shan</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/43/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3001 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">ProxyBNN: Learning Binarized Neural Networks via Proxy Matrices</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xiangyu He, Zitao Mo, Ke Cheng, Weixiang Xu, Qinghao Hu, Peisong Wang, Qingshan Liu, Jian Cheng</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2623/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1058 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">RANSAC-Flow: Generic Two-stage Image Alignment</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xi Shen, Franc cois Darmon, Alexei A. Efros, Mathieu Aubry</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">An algorithm for generic image alignment without annotations</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4880/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2202 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">RD-GAN: Few/Zero-Shot Chinese Character Style Transfer via Radical Decomposition and Rendering</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yaoxiong Huang, Mengchao He, Lianwen Jin, Yongpan Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A Chinese character style transfer model with radical decomposition and rendering</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1054/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2036 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">RTM3D: Real-time Monocular 3D Detection from Object Keypoints for Autonomous Driving</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Peixuan Li, Huaici Zhao, Pengfei Liu, Feidao Cao</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Our method is the first real-time system (FPS&gt;24) for monocular image 3D detection while achieves state-of-the-art performance on the KITTI benchmark.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2992/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3273 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Reconstructing NBA Players</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Luyang Zhu, Konstantinos Rematas, Brian Curless, Steven M. Seitz, Ira Kemelmacher-Shlizerman</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">3D reconstruction of NBA players from single images.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2495/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4311 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Region Graph Embedding Network for Zero-Shot Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Guo-Sen Xie, Li Liu, Fan Zhu, Fang Zhao, Zheng Zhang, Yazhou Yao, Jie Qin, Ling Shao</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We proposed a Region Graph Embedding Network for Zero-Shot Learning for Zero-Shot Learning and Generalized ZSL</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1101/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3029 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Rethinking Bottleneck Structure for Efficient Mobile Network Design</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Daquan Zhou, Qibin Hou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">sandglass block; residual block; efficient architecture design; image classification</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1802/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4054 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">RobustFusion: Human Volumetric Capture with Data-driven Visual Cues using a RGBD Camera</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhuo Su, Lan Xu, Zerong Zheng, Tao Yu, Yebin Liu, Lu Fang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We introduce a robust template-less human volumetric capture system combined with various data-driven visual cues, which outperforms existing state-of-the-art approaches significantly.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2215/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3256 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Rotationally-Temporally Consistent Novel View Synthesis of Human Performance Video</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Youngjoong Kwon, Stefano Petrangeli, Dahun Kim, Haoliang Wang, Eunbyung Park, Viswanathan Swaminathan, Henry Fuchs</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Our work is synthesizing novel-view video of a human performance which are rotationally and temporally coherent.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/997/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1025 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">S2DNet: Learning Image Features for Accurate Sparse-to-Dense Matching</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Hugo Germain, Guillaume Bourmaud, Vincent Lepetit</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present a novel sparse-to-dense feature matching pipeline, which outperforms traditional approaches for image matching and long-term visual localization.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2314/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4077 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">SF-Net: Single-Frame Supervision for Temporal Action Localization</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Fan Ma, Linchao Zhu, Yi Yang, Shengxin Zha, Gourab Kundu, Matt Feiszli, Zheng Shou</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6406/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4210 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">SODA: Story Oriented Dense Video Captioning Evaluation Framework</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Soichiro Fujita, Tsutomu Hirao, Hidetaka Kamigaito, Manabu Okumura, Masaaki Nagata</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4442/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2258 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">SRFlow: Learning the Super-Resolution Space with Normalizing Flow</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Andreas Lugmayr, Martin Danelljan, Luc Van Gool, Radu Timofte</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2191/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2078 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Self-supervising Fine-grained Region Similarities for Large-scale Image Localization</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yixiao Ge, Haibo Wang, Feng Zhu, Rui Zhao, Hongsheng Li</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Self-supervising image-to-region similarities for image-based localization</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5723/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2380 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Semantic Curiosity for Active Visual Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Devendra Singh Chaplot, Helen Jiang, Saurabh Gupta, Abhinav Gupta</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2632/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2255 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Arun Balajee Vasudevan, Dengxin Dai, Luc Van Gool</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Semantic object localization and depth estimation with binaural sounds, and spatial sound super-resolution</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1479/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2049 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Semi-Siamese Training for Shallow Face Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Hang Du, Hailin Shi, Yuchi Liu, Jun Wang, Zhen Lei, Dan Zeng, Tao Mei</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4545/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2189 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Semi-supervised Semantic Segmentation via Strong-weak Dual-branch Network</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Wenfeng Luo, Meng Yang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">This paper proposes a data-discriminant neural network to efficiently handle the strong and weak supervions for semi-supervised image segmentation.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5714/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4409 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Shonan Rotation Averaging: Global Optimality by Surfing $SO(p)^n$</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Frank Dellaert, David M. Rosen, Jing Wu, Robert Mahony, Luca Carlone</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Shonan Rotation Averaging is a fast, simple, and elegant rotation averaging algorithm that is guaranteed to recover globally optimal solutions under mild assumptions on the measurement noise.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2723/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4109 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Short-Term and Long-Term Context Aggregation Network for Video Inpainting</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Ang Li, Shanshan Zhao, Xingjun Ma, Mingming Gong, Jianzhong Qi, Rui Zhang, Dacheng Tao, Ramamohanarao Kotagiri</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2272/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4074 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Side-Aware Boundary Localization for More Precise Object Detection</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jiaqi Wang, Wenwei Zhang, Yuhang Cao, Kai Chen, Jiangmiao Pang, Tao Gong, Jianping Shi, Chen Change Loy, Dahua Lin</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose Side-Aware Boundary Localization, a new object localization method that localizes each boundary of the object with a bucketing scheme.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1104/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4259 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Side-Tuning: A Baseline for Network Adaptation via Additive Side Networks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jeffrey O. Zhang, Alexander Sax, Amir Zamir, Leonidas Guibas, Jitendra Malik</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Side-tuning is a simple baseline for lifelong learning and transfer learning.  It performs as well as or better than more complex existing approaches.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6490/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3221 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Sketch-Guided Object Localization in Natural Images</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Aditay Tripathi, Rajath R. Dani, Anand Mishra and Anirban Chakraborty</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6124/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1149 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Unsupervised Domain Adaptation for Semantic Segmentation of NIR Images through Generative Latent Search</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Prashant Pandey, Aayush Kumar Tyagi, Sameer Ambekar, Prathosh AP</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5116/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4182 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Efficient Spatio-Temporal Recurrent Neural Network for Video Deblurring</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhihang Zhong, Ye Gao, Yinqiang Zheng, Bo Zheng</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">lightweight but high-performance video deblurring method</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1425/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2294 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zuxuan Wu, Ser-Nam Lim, Larry S. Davis, Tom Goldstein</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We study the transferability of attacks on object detectors.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1886/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4288 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Surface Normal Estimation of Tilted Images via Spatial Rectifier</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Tien Do, Khiem Vuong, Stergios I. Roumeliotis, Hyun Soo Park</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Spatial rectifier to estimate surface normal of tilted images</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3604/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2346 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">TAO: A Large-Scale Benchmark for Tracking Any Object</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Achal Dave, Tarasha Khurana, Pavel Tokmakov, Cordelia Schmid, Deva Ramanan</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We introduce a diverse, large-scale dataset, TAO, and use it to broadly assess the state of tracking (single-object, multi-object, and person tracking).</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3089/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2121 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">TENet: Triple Excitation Network for Video Salient Object Detection</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Sucheng Ren, Chu Han, Xin Yang, Guoqiang Han, Shengfeng He</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/7231/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3316 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">The Hessian Penalty: A Weak Prior for Unsupervised Disentanglement</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">William Peebles, John Peebles, Jun-Yan Zhu, Alexei Efros, Antonio Torralba</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a simple, model-agnostic regularization technique to encourage disentanglement. The regularization term encourages the input Hessian to be diagonal in latent factors.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5393/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4393 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Joint Semantic Instance Segmentation on Graphs with the Semantic Mutex Watershed</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Steffen Wolf, Yuyan Li, Constantin Pape, Alberto Bailoni, Anna Kreshuk, Fred A. Hamprecht</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1121/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4033 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Towards Part-aware Monocular 3D Human Pose Estimation: An Architecture Search Approach</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zerui Chen, Yan Huang, Hongyuan Yu, Bin Xue, Ke Han, Yiru Guo, Liang Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present an approach to estimate 3D poses of different body parts with specially optimized neural architectures</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2342/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3260 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Tracking Objects as Points</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xingyi Zhou, Vladlen Koltun, Philipp Kr"ahenb"uhl</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present a simultaneous point-based detection and tracking system, which runs in realtime and fully online.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2402/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4309 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Transporting Labels via Hierarchical Optimal Transport for Semi-Supervised Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Fariborz Taherkhani, Ali Dabouei, Sobhan Soleymani, Jeremy Dawson, Nasser M. Nasrabadi</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1449/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3041 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">TuiGAN: Learning Versatile Image-to-Image Translation with Two Unpaired Images</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jianxin Lin, Yingxue Pang, Yingce Xia, Zhibo Chen, Jiebo Luo</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4602/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2193 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Two-Stream Consensus Network for Weakly-Supervised Temporal Action Localization</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yuanhao Zhai, Le Wang, Wei Tang, Qilin Zhang, Junsong Yuan, Gang Hua</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3601/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2345 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Unified Image and Video Saliency Modeling</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Richard Droste, Jianbo Jiao, J. Alison Noble</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We achieve state-of-the art in video saliency modeling through a unified image and video saliency modeling framework with novel domain adaptation.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/513/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2276 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yapeng Tian, Dingzeyu Li, Chenliang Xu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">pose and try to tackle a new audio-visual problem: audio-visual video parsing</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2157/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3066 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Unpaired Learning of Deep Image Denoising</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xiaohe Wu, Ming Liu, Yue Cao, Dongwei Ren, Wangmeng Zuo</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3125/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4345 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Weakly-supervised 3D Shape Completion in the Wild</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jiayuan Gu, Wei-Chiu Ma, Sivabalan Manivasagam, Wenyuan Zeng, Zihao Wang, Yuwen Xiong, Hao Su, Raquel Urtasun</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1062/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2288 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Video Object Segmentation with Episodic Graph Memory Networks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xiankai Lu, Wenguan Wang, Martin Danelljan, Tianfei Zhou, Jianbing Shen, Luc Van Gool</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2905/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2326 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">View-Invariant Probabilistic Embedding for Human Pose</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jennifer J. Sun, Jiaping Zhao, Liang-Chieh Chen, Florian Schroff, Hartwig Adam, Ting Liu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Probabilistic embeddings of human poses with view-invariant property that can be applied to pose retrieval, video alignment, and action recognition.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3684/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2153 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">VisualCOMET: Reasoning about the Dynamic Context of a Still Image</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jae Sung Park, Chandra Bhagavatula, Roozbeh Mottaghi, Ali Farhadi, Yejin Choi</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6277/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4424 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Visual Relation Grounding in Videos</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Junbin Xiao, Xindi Shang, Xun Yang, Sheng Tang, Tat-Seng Chua</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6296/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3218 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Weakly Supervised 3D Human Pose and Shape Reconstruction with Normalizing Flows</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Andrei Zanfir, Eduard Gabriel Bazavan, Hongyi Xu, William T. Freeman, Rahul Sukthankar, Cristian Sminchisescu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3477/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1086 - Spotlight
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">ETH-XGaze: A Large Scale Dataset for Gaze Estimation under Extreme Head Pose and Gaze Variation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xucong Zhang, Seonwook Park, Thabo Beeler, Derek Bradley, Siyu Tang, Otmar Hilliges</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A large scale (over 1 million samples) gaze estimation dataset with high-resolution images under extreme head poses and gaze directions.</p>
		</div>
	</a>
</div>

		</div>
		

	</div>

</div>

</div>



</body></html>