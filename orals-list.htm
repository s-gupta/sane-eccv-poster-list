<!DOCTYPE html>
<!-- saved from url=(0048)https://papers.eccv2020.eu/papers/category/oral/ -->
<html lang="en" dir="ltr"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
	<title>ECCV - Papers and Presentations</title>
	<link rel="stylesheet" href="./orals_files/uikit.min.css">
	<script src="./orals_files/jquery.min.js"></script>
	<script src="./orals_files/uikit.min.js"></script>
	<script src="./orals_files/uikit-icons.min.js"></script>
	<style type="text/css">
		#ccs-nav {
			background-color: #28a5f0;
			background-image: url("/static/images/DigitalBackground-25.png");
			background-repeat: repeat;
		}
		#ccs-nav li a {
			color: #fff;
			font-weight: bold;
		}
		#ccs-nav .uk-search {
			background-color: white;
			width: 200px;
		}
		#ccs-nav .uk-search-icon {
			width: 20px;
			padding-left: 5px;
		}
		#ccs-nav .uk-search-input {
			font-size: 1.0rem;
			padding-left: 30px;
		}
		#ccs-nav .uk-logo img {
			width: 70px;
		}
		#eccv-votes button.eccv-vote {
			background-color: #eee;
			color: #bbb;
		}
		#eccv-votes button.eccv-vote span.uk-icon {
			display: none;
		}
		#eccv-votes button.eccv-active {
			background-color: #adfb96;
			color: #22a286;
		}
		#eccv-votes button.eccv-active span.uk-icon {
			display: inline-block;
		}
		.eccv-question {
			cursor: pointer;
		}
		.eccv-question-target {
			display: none;
		}

		body {
			background-color: #eee;
			background-image: url("/static/images/DigitalBackground-15.png");
			background-repeat: repeat;
		}
		.ccs-no-profile-image {
			display: block;
			width: 40px;
			height: 40px;
			background-color: #ccc;
			border: 1px dotted #aaa;
			text-align: center;
			line-height: 40px;
			font-weight: bold;
			border-radius: 20px;
		}
	</style>
	
</head>
<body>
<nav id="ccs-nav" class="uk-navbar-container uk-navbar" uk-navbar="">
	<div class="uk-navbar-left">
		<ul class="uk-navbar-nav">
			<li><a class="uk-navbar-item uk-logo" href="https://papers.eccv2020.eu/"><img src="./orals_files/eccv-online-logo_A.png" alt="ECCV Online"></a></li>
			<li><a class="uk-navbar-item" href="https://papers.eccv2020.eu/">Papers and Presentations</a></li>
		</ul>
	</div>
	<div class="uk-navbar-right">
		<div class="uk-navbar-item">
			<form method="GET" action="https://papers.eccv2020.eu/papers/search/" class="uk-search uk-search-navbar">
				<span uk-search-icon="" class="uk-icon uk-search-icon"><svg width="24" height="24" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" data-svg="search-navbar"><circle fill="none" stroke="#000" stroke-width="1.1" cx="10.5" cy="10.5" r="9.5"></circle><line fill="none" stroke="#000" stroke-width="1.1" x1="23" y1="23" x2="17" y2="17"></line></svg></span>
				<input class="uk-search-input uk-form-small" name="q" type="search" placeholder="Search...">
			</form>
		</div>
		<ul class="uk-navbar-nav">
			
				<li><a href="https://papers.eccv2020.eu/">saurabhg@illinois.edu</a></li>
			
		</ul>
	</div>
</nav>
<div class="uk-container uk-padding-large">

<div class="uk-grid-small uk-flex-center uk-grid uk-grid-stack" uk-grid="">
	<div class="uk-width-1-1 uk-first-column">
		<h2>Papers in Category Oral</h2>

		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3029/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4341 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">A Competence-aware Curriculum for Visual Concepts Learning via Question Answering</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Qing Li, Siyuan Huang, Yining Hong, Song-Chun Zhu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a competence-aware curriculum learning approach based on Item Response Theory for visual concept learning.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1969/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2307 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">A Consistently Fast and Globally Optimal Solution to the Perspective-n-Point Problem</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">George Terzakis, Manolis Lourakis</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A fast and simple solution to the PnP with efficiency on par with that of polynomial solvers.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5360/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1135 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">A Simple Way to Make Neural Networks Robust Against Diverse Image Corruptions</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Evgenia Rusak, Lukas Schott, Roland S. Zimmermann, Julian Bitterwolf, Oliver Bringmann, Matthias Bethge, Wieland Brendel</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We show that training against properly tuned i.i.d. noise achieves state-of-the-art results on ImageNet-C and that an adversarial approach to noise training yields further improvements.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3582/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1178 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Adversarial Generative Grammars for Human Activity Prediction</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">AJ Piergiovanni, Anelia Angelova, Alexander Toshev, Michael S. Ryoo</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Introduce a new model for long-term future prediction</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/445/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2272 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">AiR: Attention with Reasoning Capability</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Shi Chen, Ming Jiang, Jinhui Yang, Qi Zhao</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2834/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4320 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Aligning and Projecting Images to Class-conditional Generative Networks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Minyoung Huh, Richard Zhang, Jun-Yan Zhu, Sylvain Paris, Aaron Hertzmann</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">BasinCMA + optimizing for transformation = better image projection</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2788/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3187 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Appearance Consensus Driven Self-Supervised Human Mesh Recovery</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jogendra Nath Kundu, Mugalodi Rakesh, Varun Jampani, Rahul Mysore Venkatesh, R. Venkatesh Babu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3183/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4129 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Appearance-Preserving 3D Convolution for Video-based Person Re-identification</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xinqian Gu, Hong Chang, Bingpeng Ma, Hongkai Zhang, Xilin Chen</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">In this paper, we propose Appearance-Preserving 3D convolution to address the appearance destruction problem of existing 3D convolution.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2211/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4069 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">BorderDet: Border Feature for Dense Object Detection</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Han Qiu, Yuchen Ma, Zeming Li, Songtao Liu, Jian Sun</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Extract effective border feature for object detections.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3439/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1084 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">CoReNet: Coherent 3D Scene Reconstruction from a Single RGB Image</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Stefan Popov, Pablo Bauszat, Vittorio Ferrari</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">3D Reconstruction of multiple objects from a single RGB image</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3356/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1078 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Combining Implicit Function Learning and Parametric Models for 3D Human Reconstruction</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Bharat Lal Bhatnagar, Cristian Sminchisescu, Christian Theobalt, Gerard Pons-Moll</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Fit 3D parametric model to implicit reconstructions of digital humans</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1417/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3039 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jiuniu Wang, Wenjia Xu, Qingzhong Wang, Antoni B. Chan</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose Between-set CIDEr (CIDErBtw) to measure the distinctiveness of captions by comparing to its similar images, and apply CIDErBtw to reweight ground truth captions in training process, achieving distinctive captions with SOTA accuracy.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1105/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4032 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Conditional Convolutions for Instance Segmentation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhi Tian, Chunhua Shen, Hao Chen</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A new and simpler instance segmentation framework with state-of-the-art performance and speed.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3544/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2150 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Content Adaptive and Error Propagation Aware Deep Video Compression</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Guo Lu, Chunlei Cai, Xiaoyun Zhang, Li Chen, Wanli Ouyang, Dong Xu, Zhiyong Gao</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2503/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4094 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Content-Aware Unsupervised Deep Homography Estimation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jirong Zhang, Chuan Wang, Shuaicheng Liu, Lanpeng Jia, Nianjin Ye, Jue Wang, Ji Zhou, Jian Sun</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Homography; deep homography; image alignment; RANSAC</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3976/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1099 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Cross-Domain Cascaded Deep Translation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Oren Katzir, Dani Lischinski, Daniel Cohen-Or</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Image-to-image translation and synthesis in a cascaded, deep-to-shallow, fashion, along the deep feature of a pre-trained classification network</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/736/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4248 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Crowdsampling the Plenoptic Function</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhengqi Li, Wenqi Xian, Abe Davis, Noah Snavely</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2149/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3065 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Deep Fashion3D: A Dataset and Benchmark for 3D Garment Reconstruction from Single Images</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Heming Zhu, Yu Cao, Hang Jin, Weikai Chen, Dong Du, Zhangye Wang, Shuguang Cui, Xiaoguang Han</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3312/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2138 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Deep Spatial-angular Regularization for Compressive Light Field Reconstruction over Coded Apertures</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Mantang Guo, Junhui Hou, Jing Jin, Jie Chen, Lap-Pui Chau</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/283/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4004 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">DeepFit: 3D Surface Fitting via Neural Network Weighted Least Squares</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yizhak Ben-Shabat, Stephen Gould</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Surface fitting for unstructured 3D point clouds using neural networks to learn weights for solving a weighted least squares problem. Used for normal estimation, principal curvature estimation, noise removal and surface reconstruction.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3538/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4145 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">DeepHandMesh: A Weakly-supervised Deep Encoder-Decoder Framework for High-fidelity Hand Mesh Modeling</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Gyeongsik Moon, Takaaki Shiratori, Kyoung Mu Lee</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Weakly-supervised high-fidelity hand mesh modeling from a single RGB image.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/840/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4251 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">DeepSFM: Structure From Motion Via Deep Bundle Adjustment</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xingkui Wei, Yinda Zhang, Zhuwen Li, Yanwei Fu, Xiangyang Xue</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We design a physical driven deep architecture for depth and pose estimation inspired by Bundle Ajustment.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/384/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4232 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Describing Textures using Natural Language</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Chenyun Wu, Mikayla Timm, Subhransu Maji</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A novel dataset of textures with natural language descriptions and analysis of several language and vision models</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2825/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2323 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Diffraction Line Imaging</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Mark Sheinin, Dinesh N. Reddy, Matthew O'Toole, Srinivasa G. Narasimhan</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present a novel approach for positioning light sources in 2D using line sensors and diffraction.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3528/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2344 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Domain-invariant Stereo Matching Networks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Feihu Zhang, Xiaojuan Qi, Ruigang Yang, Victor Prisacariu, Benjamin Wah, Philip Torr</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">When trained only with synthetic/simulation data, our DSMNet is the first work that outperforms deep neural network models (e.g. DispNet, MCCNN) trained on real data.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2263/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2084 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Du$^2$Net: Learning Depth Estimation from Dual-Cameras and Dual-Pixels</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yinda Zhang, Neal Wadhwa, Sergio Orts-Escolano, Christian H"a}ne, Sean Fanello, Rahul Garg</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3948/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2170 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">EagleEye: Fast Sub-net Evaluation for Efficient Neural Network Pruning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Bailin Li, Bowen Wu, Jiang Su, Guangrun Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2597/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4316 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">The Phong Surface: Efficient 3D Model Fitting using Lifted Optimization</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jingjing Shen, Thomas J. Cashman, Qi Ye, Tim Hutton, Toby Sharp, Federica Bogo, Andrew Fitzgibbon, Jamie Shotton</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/410/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2011 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Empowering Relational Network by Self-Attention Augmented Conditional Random Fields for Group Activity Recognition</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Rizard Renanda Adhi Pramono, Yie Tarng Chen, Wen Hsien Fang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/738/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3016 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">VoxelPose: Towards Multi-Camera 3D Human Pose Estimation in Wild Environment</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Hanyue Tu, Chunyu Wang, Wenjun Zeng</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/832/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3170 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">End-to-End Object Detection with Transformers</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">End-to-end single pass object detection with transformers and parallel set prediction</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6502/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2238 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">ExchNet: A Unified Hashing Network for Large-Scale Fine-Grained Image Retrieval</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Quan Cui, Qing-Yuan Jiang, Xiu-Shen Wei, Wu-Jun Li, Osamu Yoshie</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3265/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2134 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Exploiting Deep Generative Prior for Versatile Image Restoration and Manipulation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xingang Pan, Xiaohang Zhan, Bo Dai, Dahua Lin, Chen Change Loy, Ping Luo</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1203/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3239 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Fashionpedia: Ontology, Segmentation, and an Attribute Localization Dataset</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Menglin Jia, Mengyun Shi, Mikhail Sirotenko, Yin Cui, Claire Cardie, Bharath Hariharan, Hartwig Adam, Serge Belongie</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2641/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2319 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Miao Liu, Siyu Tang, Yin Li, James M. Rehg</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present a novel probabilistic  deep model that jointly predicts future hand trajectory, interaction hotspots, and action labels in First Person Vision</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6147/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4206 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">ForkGAN: Seeing into the Rainy Night</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Ziqiang Zheng, Yang Wu, Xinran Han, Jianbo Shi</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2471/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4092 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Gradient Centralization: A New Optimization Technique for Deep Neural Networks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Hongwei Yong, Jianqiang Huang, Xiansheng Hua, Lei Zhang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a simple yet effective optimization technique for DNNs by centralizing the gradient of weight vector.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3587/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1093 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">GDumb: A Simple Approach that Questions Our Progress in Continual Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Ameya Prabhu, Philip H. S. Torr, Puneet K. Dokania</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a simple algorithm following the general set-up for CL for image classification which is surprisingly effective and obtains state-of-the-art results</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5800/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2223 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Hierarchical Face Aging through Disentangled Latent Characteristics</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Peipei Li, Huaibo Huang, Yibo Hu, Xiang Wu, Ran He, Zhenan Sun</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/677/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2277 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">House-GAN: Relational Generative Adversarial Networks for Graph-constrained House Layout Generation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Nelson Nauata, Kai-Hung Chang, Chin-Yi Cheng, Greg Mori, Yasutaka Furukawa</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Relational Generative Adversarial Networks for Graph-constrained House Layout Generation</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5859/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4197 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Hybrid Models for Open Set Recognition</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Hongjie Zhang, Ang Li, Jie Guo, Yanwen Guo</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3112/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2124 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Improving Deep Video Compression by Resolution-adaptive Flow Coding</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhihao Hu, Zhenghao Chen, Dong Xu, Guo Lu, Wanli Ouyang, Shuhang Gu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Resolution-adaptive flow coding with rate-distortion criterion for deep video compression.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2978/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4333 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">In-Home Daily-Life Captioning Using Radio Signals</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Lijie Fan, Tianhong Li, Yuan Yuan, Dina Katabi</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A new model for captioning daily life by analyzing the privacy-preserving radio signal in the home with the home's floormap.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3975/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3199 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Intrinsic Point Cloud Interpolation via Dual Latent Space Navigation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Marie-Julie Rakotosaona, Maks Ovsjanikov</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present a learning-based method for interpolating and manipulating 3D shapes represented as point clouds, that is explicitly designed to preserve intrinsic shape properties.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/529/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2015 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Invertible Image Rescaling</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Mingqing Xiao, Shuxin Zheng, Chang Liu, Yaolong Wang, Di He, Guolin Ke, Jiang Bian, Zhouchen Lin, Tie-Yan Liu </p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A light-weight model for downscaling high-resolution image and restoring it with high-quality.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4423/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4376 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">It is not the Journey but the Destination: Endpoint Conditioned Trajectory Prediction</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Karttikeya Mangalam, Harshayu Girase, Shreyas Agarwal, Kuan-Hui Lee, Ehsan Adeli, Jitendra Malik, Adrien Gaidon</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present PECNet, a pedestrian endpoint conditioned trajectory prediction network that conditions trajectory predictions on sampled endpoints &amp; achieves SOTA on several benchmarks.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2974/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2331 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Joint Disentangling and Adaptation for Cross-Domain Person Re-Identification</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yang Zou, Xiaodong Yang, Zhiding Yu, B.V.K. Vijaya Kumar, Jan Kautz</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4866/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1124 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">LIMP: Learning Latent Shape Representations with Metric Preservation Priors</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Luca Cosmo, Antonio Norelli, Oshri Halimi, Ron Kimmel, Emanuele Rodol`a</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">In the context of deep generative models for deformable 3D shapes, we show how connecting the Euclidean metric on the latent space to the geodesic distortion of the decoded shapes induces a strong regularization on the learned latent space.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1044/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1026 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Ladybird: Quasi-Monte Carlo Sampling for Deep Implicit Field Based 3D Reconstruction with Symmetry</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yifan Xu, Tianqi Fan, Yi Yuan, Gurprit Singh</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3482/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2342 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Layer-wise Conditioning Analysis in Exploring the Learning Dynamics of DNNs</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Lei Huang, Jie Qin, Li Liu, Fan Zhu, Ling Shao</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose layer-wise conditioning analysis and apply this analysis in investigating Batch Normalization and Residual Networks.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2096/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4068 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learn to Recover Visible Color for Video Surveillance in a Day</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Guangming Wu, Yinqiang Zheng, Zhiling Guo, Zekun Cai, Xiaodan Shi, Xin Ding, Yifei Huang, Yimin Guo, Ryosuke Shibasaki</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Video Surveillance in a Day, Color Recovery, State Synchronization Network</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2784/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2321 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning Feature Descriptors using Camera Pose Supervision</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Qianqian Wang, Xiaowei Zhou, Bharath Hariharan, Noah Snavely</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3622/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4353 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning Lane Graph Representations for Motion Forecasting</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Ming Liang, Bin Yang, Rui Hu, Yun Chen, Renjie Liao, Song Feng, Raquel Urtasun</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose the lane graph network to learn structured map representation for motion forecasting.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2683/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4318 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning Stereo from Single Images</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jamie Watson, Oisin Mac Aodha, Daniyar Turmukhambetov, Gabriel J. Brostow, Michael Firman</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We show that is possible to train state-of-the-art stereo networks from unstructured collections of single images and without any synthetic data.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4440/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3207 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning What to Learn for Video Object Segmentation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Goutam Bhat, Felix J"a}remo Lawin, Martin Danelljan, Andreas Robinson, Michael Felsberg, Luc Van Gool, Radu Timofte vspace1.5mm</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1793/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3176 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning and Aggregating Deep Local Descriptors for Instance-level Recognition</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Giorgos Tolias, Tomas Jenicek, Ondv r}ej Chum</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">deep local feature detection and description trained jointly</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6101/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4204 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Learning to Localize Actions from Moments</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Fuchen Long, Ting Yao, Zhaofan Qiu, Xinmei Tian, Jiebo Luo, Tao Mei</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1448/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4275 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Long-term Human Motion Prediction with Scene Context</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhe Cao, Hang Gao, Karttikeya Mangalam, Qi-Zhi Cai, Minh Vo, Jitendra Malik</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4043/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2173 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">"Look Ma, no landmarks!'' -- Unsupervised, Model-based Dense Face Alignment</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Tatsuro Koizumi, William A. P. Smith</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Use an image-to-image network to regress dense correspondence to a 3D morphable model, solve for geometry least squares, then solve for lighting/texture least squares = unsupervised training!</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3772/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3197 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Mapillary Planet-Scale Depth Dataset</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Manuel L'o}pez Antequera, Pau Gargallo, Markus Hofinger, Samuel Rota Bul`o, Yubin Kuang, Peter Kontschieder</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Very large rgb + (metric) depth dataset from street-level imagery</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1737/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1171 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">MatryODShka: Real-time 6DoF Video View Synthesis using Multi-Sphere Images</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Benjamin Attal, Selena Ling, Aaron Gokaslan, Christian Richardt, James Tompkin</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Inferring multi-sphere images from ODS video for real-time 6DoF VR.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3387/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1081 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Guolei Sun, Wenguan Wang, Jifeng Dai, Luc Van Gool</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/343/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2009 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">NSGANetV2: Evolutionary Multi-Objective Surrogate-Assisted Neural Architecture Search</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhichao Lu, Kalyanmoy Deb, Erik Goodman, Wolfgang Banzhaf, Vishnu Naresh Boddeti</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">An efficient multi-objective neural architecture search algorithm through online surrogate modeling</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2307/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3073 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Model-Agnostic Boundary-Adversarial Sampling for Test-Time Generalization in Few-Shot learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jaekyeom Kim, Hyoungseok Kim, Gunhee Kim</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a novel model-agnostic approach for few-shot classification as the first pure test-time method that creates samples adversarial to the classification boundaries and use them to fine-tune the embedding function.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3158/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4127 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Motion Capture from Internet Videos</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Junting Dong, Qing Shuai, Yuanqing Zhang, Xian Liu, Xiaowei Zhou, Hujun Bao</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2556/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1050 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Multi-View Optimization of Local Feature Geometry</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Mihai Dusmanu, Johannes L. Sch"o}nberger, Marc Pollefeys</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Multi-view refinement of local features to improve keypoint localization accuracy for Structure-from-Motion.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3047/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3274 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Multitask Learning Strengthens Adversarial Robustness</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Chengzhi Mao, Amogh Gupta, Vikram Nitin, Baishakhi Ray, Shuran Song, Junfeng Yang, Carl Vondrick</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Multi-task learning increases adversarial robustness for both the entire model and individual tasks.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1196/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2292 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">MutualNet: Adaptive ConvNet via Mutual Learning from Network Width and Resolution</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Taojiannan Yang, Sijie Zhu, Chen Chen, Shen Yan, Mi Zhang, Andrew Willis</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1473/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4278 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Optimizing an MLP to map from position and direction to color and volume density enables state-of-the-art view synthesis.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4158/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1109 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Online Invariance Selection for Local Feature Descriptors</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">R'e}mi Pautrat, Viktor Larsson, Martin R. Oswald, Marc Pollefeys</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a method to learn multiple invariances for local feature descriptors and to select the most adapted invariance when matching feature points.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3376/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2142 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Orientation-aware Vehicle Re-identification with Semantics-guided Part Attention Network</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Tsai-Shien Chen, Chih-Ting Liu, Chih-Wei Wu, Shao-Yi Chien</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2949/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4328 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Post-Training Piecewise Linear Quantization for Deep Neural Networks</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jun Fang, Ali Shafiee, Hamzah Abdel-Aziz, David Thorsley, Georgios Georgiadis, Joseph H. Hassoun</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We present a piecewise linear quantization scheme for accurate post-training quantization of deep neural networks.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1273/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1031 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Privacy Preserving Structure-from-Motion</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Marcel Geppert, Viktor Larsson, Pablo Speciale, Johannes L. Schönberger, Marc Pollefeys</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Privacy Preserving Structure from Motion</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2748/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4111 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Prototype Rectification for Few-Shot Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jinlu Liu, Liang Song, Yongqiang Qin</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A simple yet effective method for prototype rectification by reducing the intra-class bias and the cross-class bias.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/267/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1007 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Quaternion Equivariant Capsule Networks for 3D Point Clouds</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yongheng Zhao, Tolga Birdal, Jan Eric Lenssen, Emanuele Menegatti, Leonidas Guibas, Federico Tombari</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3526/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4348 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">RAFT: Recurrent All-Pairs Field Transforms for Optical Flow</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zachary Teed, Jia Deng</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1501/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2299 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">ReferIt3D: Neural Listeners for Fine-Grained 3D Object Identification in Real-World Scenes</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Panos Achlioptas, Ahmed Abdelreheem, Fei Xia, Mohamed Elhoseiny, Leonidas Guibas</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Creating visio-linguistic data and accompanying neural models that enable comprehension of natural language that identifies 3D objects placed in real-world scenes</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2258/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2083 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Regularization with Latent Space Virtual Adversarial Training</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Genki Osada, Budrul Ahsan, Revoti Prasad Bora, Takashi Nishide</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4179/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2182 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Rethinking Image Inpainting via a Mutual Encoder-Decoder with Feature Equalizations</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Hongyu Liu, Bin Jiang, Yibing Song, Wei Huang, Chao Yang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Rethinking image inpainting via a mutual encoder-decoder with feature equalization</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1326/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4267 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Rewriting a Deep Generative Model</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">David Bau, Steven Liu, Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We rewrite specific rules inside deep generative models interactively, by treating each layer as an associative memory.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3054/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3090 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">S2DNAS: Transforming Static CNN Model for Dynamic Inference via Neural Architecture Search</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhihang Yuan, Bingzhe Wu, Guangyu Sun, Zheng Liang, Shiwan Zhao, Weichen Bi</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4732/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3209 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">SIZER: A Dataset and Model for Parsing 3D Clothing and Learning Size Sensitive 3D Clothing</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Garvita Tiwari, Bharat Lal Bhatnagar, Tony Tung, Gerard Pons-Moll</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A model for 3D garment parsing and clothing size variation with dataset of clothing size variation.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/1059/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4029 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Segment as Points for Efficient Online Multi-Object Tracking and Segmentation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhenbo Xu, Wei Zhang, Xiao Tan, Wei Yang, Huan Huang, Shilei Wen, Errui Ding, Liusheng Huang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Segment as Points for Efficient Online Multi-Object Tracking and Segmentation</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/500/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2250 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Self6D: Self-Supervised Monocular 6D Object Pose Estimation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Gu Wang, Fabian Manhardt, Jianzhun Shao, Xiangyang Ji, Nassir Navab, Federico Tombari</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a novel approach for self-supervised monocular 6D object pose estimation without real world annotations by enforcing visual and geometric alignment based on neural rendering.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3018/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4340 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Self-Challenging Improves Cross-Domain Generalization</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zeyi Huang, Haohan Wang, Eric P. Xing, Dong Huang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2785/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2114 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Semantic Flow for Fast and Accurate Scene Parsing</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xiangtai Li, Ansheng You, Zhen Zhu, Houlong Zhao, Maoke Yang, Kuiyuan Yang, Shaohua Tan, Yunhai Tong </p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5457/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1141 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">SoftPoolNet: Shape Descriptor for Point Cloud Completion and Classification</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yida Wang, David Joseph Tan, Nassir Navab, Federico Tombari</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">SoftPoolNet: Shape Descriptor for Point Cloud Completion and Classification</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3241/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3099 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Solving the Blind Perspective-n-Point Problem End-To-End With Robust Differentiable Geometric Optimization</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Dylan Campbell, Liu Liu, Stephen Gould</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2193/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3068 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Spatially Adaptive Inference with Stochastic Feature Sampling and Interpolation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Zhenda Xie, Zheng Zhang, Xizhou Zhu, Gao Huang, Stephen Lin</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2852/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3088 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Suppress and Balance: A Simple Gated Network for Salient Object Detection</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xiaoqi Zhao, Youwei Pang, Lihe Zhang, Huchuan Lu, Lei Zhang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a novel  GateNet for RGB salient object detection, which is easy to follow.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3678/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4357 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Synthesis and Completion of Facades from Satellite Imagery</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xiaowei Zhang, Christopher May, Daniel Aliaga</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/612/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4242 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Synthesize then Compare: Detecting Failures and Anomalies for Semantic Segmentation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Yingda Xia, Yi Zhang, Fengze Liu, Wei Shen, Alan L. Yuille</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/6209/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3161 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">TCGM: An Information-Theoretic Framework for Semi-Supervised Multi-Modality Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xinwei Sun, Yilun Xu, Peng Cao, Yuqing Kong, Lingjing Hu, Shanghang Zhang, Yizhou Wang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a novel TCGM for semi-supervised multi-modality learning, which has theoretical guarantee and can achieve state-of-the-art results on various dataset.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2463/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2104 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Targeted Attack for Deep Hashing based Retrieval</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Jiawang Bai, Bin Chen, Yiming Li, Dongxian Wu, Weiwei Guo, Shu-Tao Xia, En-Hui Yang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">We propose a novel targeted attack for deep hashing based retrieval, and provide theoretical and empirical results.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/4358/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4371 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">TextCaps: a Dataset for Image Captioning with Reading Comprehension</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Oleksii Sidorov, Ronghang Hu, Marcus Rohrbach, Amanpreet Singh</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A new task, a large collected dataset, and extensive analysis of Image Captioning with Reading Comprehension.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5932/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4417 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">TopoGAN: A Topology-Aware Generative Adversarial Network</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Fan Wang, Huidong Liu, Dimitris Samaras, Chao Chen</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">TopoGAN with a topology loss on generator</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3570/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#1091 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Towards Automated Testing and Robustification by Semantic Adversarial Data Generation</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Rakshith Shetty, Mario Fritz, Bernt Schiele</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Synthesize plausible but atypical hard examples by semantic adversarial editing of object appearance, which is then used to evaluate and improve the robustness of object detectors.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3553/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4349 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Towards Streaming Perception</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Mengtian Li, Yu-Xiong Wang, Deva Ramanan</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A meta-benchmark, analysis and solutions for streaming perception, which recognizes the fact that by the time an algorithm finishes processing a particular image frame, the surrounding world has changed.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3891/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2167 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Training Interpretable Convolutional Neural Networks by Differentiating Class-specific Filters</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Haoyu Liang, Zhihao Ouyang, Yuyuan Zeng, Hang Su, Zihao He, Shu-Tao Xia, Jun Zhu, Bo Zhang</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">An interpretable CNN training technique with learnable gates that induces differentiation in convolutional filters towards responding to only one (or few) class.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/5277/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#2216 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Unsupervised Sketch to Photo Synthesis</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Runtao Liu, Qian Yu, Stella X. Yu</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">sketch-based photo synthesis, sketch synthesis, cross-modality, image translation</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3838/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3287 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">V2VNet: Vehicle-to-Vehicle Communication for Joint Perception and Prediction</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Tsun-Hsuan Wang, Sivabalan Manivasagam, Ming Liang, Bin Yang, Wenyuan Zeng, Raquel Urtasun</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3331/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3106 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Video-based Remote Physiological Measurement via Cross-verified Feature Disentangling</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Xuesong Niu, Zitong Yu, Hu Han, Xiaobai Li, Shiguang Shan, Guoying Zhao</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom"></p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/2904/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#4324 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">Visual Memorability for Robotic Interestingness via Unsupervised Online Learning</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Chen Wang, Wenshan Wang, Yuheng Qiu, Yafei Hu, Sebastian Scherer</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">Propose an unsupervised online learning method for robotic visual interestingness.</p>
		</div>
	</a>
</div>

		</div>
		
		<div class="uk-card uk-card-default uk-margin-bottom">
			<div class="uk-card-body">
	<a class="uk-link-toggle" href="https://papers.eccv2020.eu/paper/3651/">
		<div>
			<h5 class="uk-text-meta uk-text-uppercase uk-margin-remove-bottom">
				#3196 - Oral
			</h5>
			<h4 class="uk-link-heading uk-margin-small-bottom uk-margin-remove-top">What Matters in Unsupervised Optical Flow</h4>
			<p class="uk-text-meta uk-text-italic uk-margin-remove-top uk-margin-remove-bottom">Rico Jonschkowski, Austin Stone, Jonathan T. Barron, Ariel Gordon, Kurt Konolige, Anelia Angelova</p>
			<p class="uk-margin-small-top uk-margin-remove-bottom">A simple unsupervised optical flow method that improves SOTA and performs comparable to supervised FlowNet2</p>
		</div>
	</a>
</div>

		</div>
		

	</div>

</div>

</div>



</body></html>